前面我们了解到，模型类中的 `manager` 对象，把 `QuerySet` 中的所有公共方法都拷贝了过来，接下来，我们再去扒一扒它的源码

代码位于：`django.db.models.query.QuerySet()`

老规矩，先看`__init__`

```python
class QuerySet:
    def __init__(self, model=None, query=None, using=None, hints=None):
        self.model = model  # 绑定的模型类，例如：<class 'wiki_app.models.Post'>
        self._db = using  # 使用哪个数据库，默认是配置中 default
        self._hints = hints or {}
        self._query = query or sql.Query(self.model) # 关联的 Query 查询类
        self._result_cache = None  # 缓存结果
        self._sticky_filter = False
        self._for_write = False
        self._prefetch_related_lookups = ()
        self._prefetch_done = False
        self._known_related_objects = {}  # {rel_field: {pk: rel_obj}}
        self._iterable_class = ModelIterable
        self._fields = None
        self._defer_next_filter = False
        self._deferred_filter = None
# 没什么特殊的，就是初始化了一些属性
```

## 1. 如何套娃？

相信使用过Django的朋友们都应该知道，queryset 对象是一个会反复套娃的对象，什么意思呢？

```python
# 理论上，一个 queryset 对象可以实现无限的链式调用。返回的结果仍然是一个 queryset 对象
Post.objects.filter(author="xxx").filter(title="yyy")
```

```python
  # 主要依赖于下面这两个方法
  
  def _chain(self):
        """
        该方法会返回当前查询集的一个副本，他的副本也是一个 queryset 
        副本查询集用于存储新的查询结果
        """
        obj = self._clone()
        if obj._sticky_filter:
            obj.query.filter_is_sticky = True
            obj._sticky_filter = False
        return obj

    
   def _clone(self):
        """
					返回当前 QuerySet 的副本
        """
      	# 重新实例化了一个新的 queryset 对象
        # 并且设置了一些属性
        # query=self.query.chain()，查询对象也使用副本，这个留到研究 query 对象再看
        c = self.__class__(model=self.model, query=self.query.chain(), using=self._db, hints=self._hints)
        c._sticky_filter = self._sticky_filter
        c._for_write = self._for_write
        c._prefetch_related_lookups = self._prefetch_related_lookups[:]
        c._known_related_objects = self._known_related_objects
        c._iterable_class = self._iterable_class
        c._fields = self._fields
        # 返回新实例化的 queryset 对象
        return c
```

## 2. 一些魔法方法

### 2.1 切片

```python
# 这个魔术方法，实现了 queryset 切片的功能
# 类似于：queryset = Post.objects.all()[1:3]、queryset = Post.objects.all()[1]
class QuerySet:
    def __getitem__(self, k):
        """
        k的有两种形式：
        	[1]： int类型
        	[1:3]:  slice类型
        """
        # k 必须为上面两种类型才行
        if not isinstance(k, (int, slice)):
            raise TypeError(
                'QuerySet indices must be integers or slices, not %s.'
                % type(k).__name__
            )
        # k 不能小于 0
        if (
            (isinstance(k, int) and k < 0) or
            (isinstance(k, slice) and (
                (k.start is not None and k.start < 0) or
                (k.stop is not None and k.stop < 0)
            ))
        ):
            raise ValueError('Negative indexing is not supported.')

        # 判断缓存中是否有结果，若有结果，将会直接返回
        if self._result_cache is not None:
            return self._result_cache[k]

        # 如果 k 是 [1:3] 的形式
        if isinstance(k, slice):
          	
            # 创建新的 queryset 对象
            qs = self._chain()
            if k.start is not None:
                start = int(k.start)
            else:
                start = None
            if k.stop is not None:
                stop = int(k.stop)
            else:
                stop = None
            # 给 query 对象添加 limits 参数。这个放到后面 query 对象再做研究
            qs.query.set_limits(start, stop)
            # 如果 k 设置了步长，就按照步长取值，否则直接返回 qs
            return list(qs)[::k.step] if k.step else qs
				# 如果 k 是 int 类型的索引
        # 创建副本 queryset
        qs = self._chain()
        # 设置副本 queryset 的 query
        qs.query.set_limits(k, k + 1)
        # 执行 _fetch_all()
        qs._fetch_all()
        return qs._result_cache[0]
```

### 2.2 迭代

我们知道 `queryset` 对象是可以通过 `for...in...` 语句进行迭代的

那么一定是实现了迭代器的协议，才能执行迭代的操作

```python
# queryset 内部实现了这个魔术方法，意味着 queryset 是一个可迭代对象
def __iter__(self):
  self._fetch_all()
  # 它返回了一个迭代器
  # self._result_cache 是一个支持迭代的集合对象, 通过调用它的 __next__, 就可以实现迭代
  return iter(self._result_cache)
```

```python
def _fetch_all(self):
  # 如果缓存结果为None
  if self._result_cache is None:
    # 返回一个列表
    self._result_cache = list(self._iterable_class(self))
  if self._prefetch_related_lookups and not self._prefetch_done:
    self._prefetch_related_objects()
```

```python
# self._iterable_class = ModelIterable
# 上面我们发现缓存结果是一个列表，包含  ModelIterable 的一个列表
class BaseIterable:
    def __init__(self, queryset, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
        self.queryset = queryset  # queryset 对象
        self.chunked_fetch = chunked_fetch
        self.chunk_size = chunk_size


class ModelIterable(BaseIterable):
    """Iterable that yields a model instance for each row."""
		
    # 返回的是一个生成器
    def __iter__(self):
        queryset = self.queryset
        db = queryset.db
        compiler = queryset.query.get_compiler(using=db)
				
        # 执行 sql 语句，获取语句执行结果
        # compiler 对象，后面也会再学到
        results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)
        select, klass_info, annotation_col_map = (compiler.select, compiler.klass_info,
                                                  compiler.annotation_col_map)
        model_cls = klass_info['model']
        select_fields = klass_info['select_fields']
        model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1
        init_list = [f[0].target.attname
                     for f in select[model_fields_start:model_fields_end]]
        related_populators = get_related_populators(klass_info, select, db)
        known_related_objects = [
            (field, related_objs, operator.attrgetter(*[
                field.attname
                if from_field == 'self' else
                queryset.model._meta.get_field(from_field).attname
                for from_field in field.from_fields
            ])) for field, related_objs in queryset._known_related_objects.items()
        ]
        # 遍历SQl语句查询结果
        for row in compiler.results_iter(results):
            obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end])
            for rel_populator in related_populators:
                rel_populator.populate(row, obj)
            if annotation_col_map:
                for attr_name, col_pos in annotation_col_map.items():
                    setattr(obj, attr_name, row[col_pos])

            # Add the known related objects to the model.
            for field, rel_objs, rel_getter in known_related_objects:
                # Avoid overwriting objects loaded by, e.g., select_related().
                if field.is_cached(obj):
                    continue
                rel_obj_id = rel_getter(obj)
                try:
                    rel_obj = rel_objs[rel_obj_id]
                except KeyError:
                    pass  # May happen in qs1 | qs2 scenarios.
                else:
                    setattr(obj, field.name, rel_obj)

            yield obj
```

## 3. 保存对象

```python
# 在 Model 对象中，当我们执行 save 方法的时候， 最终会调用 manager 的 _insert 方法
# 但是 manager 本身是没有这个方法的，这个方法是拷贝 Queryset 中的方法

def _do_insert(self, manager, using, fields, returning_fields, raw):
  return manager._insert(
    [self], fields=fields, returning_fields=returning_fields,using=using, raw=raw,
  )
```

```python
def _insert(self, objs, fields, returning_fields=None, raw=False, using=None, ignore_conflicts=False):
  self._for_write = True
  if using is None:
    using = self.db
    query = sql.InsertQuery(self.model, ignore_conflicts=ignore_conflicts)
    query.insert_values(fields, objs, raw=raw)
    return query.get_compiler(using=using).execute_sql(returning_fields)
```

接下来就交给 query 进行处理。我们放到下一篇在看